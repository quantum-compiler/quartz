{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f06b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch[22:17:35] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /home/zikunli/anaconda3/envs/quantum/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "import quartz\n",
    "quartz_context = quartz.QuartzContext(gate_set=['h', 'cx', 'x', 't', 'tdg', 'ccz'], filename='../bfs_verified_simplified.json')\n",
    "parser = quartz.PyQASMParser(context=quartz_context)\n",
    "# my_dag = parser.load_qasm(filename=\"../circuit/voqc-benchmarks/tof_4.qasm\")\n",
    "# my_dag = parser.load_qasm(filename=\"../circuit/nam-circuits/qasm_files/tof_4_before.qasm\")\n",
    "my_dag = parser.load_qasm(filename=\"barenco_tof_3_opt_path/subst_history_39.qasm\")\n",
    "init_graph = quartz.PyGraph(context=quartz_context, dag=my_dag)\n",
    "print(init_graph.num_nodes)\n",
    "# init_graph = init_graph.toffoli_flip(context=quartz_context, target=\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f25615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gate_type_num = 26\n",
    "class QAgent:\n",
    "    def __init__(self, lr, gamma,a_size, pretrained_model=None):\n",
    "        torch.manual_seed(42)\n",
    "        if pretrained_model != None:\n",
    "            self.q_net = copy.deepcopy(pretrained_model)\n",
    "        else:\n",
    "            self.q_net = QGNN(gate_type_num, 16, a_size, 16)\n",
    "        self.target_net = copy.deepcopy(self.q_net)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr = lr)\n",
    "        self.a_size = a_size \n",
    "        self.gamma = gamma\n",
    "               \n",
    "    def select_a(self, g, dgl_g, e):\n",
    "        a_size = self.a_size\n",
    "        \n",
    "        if random.random() < e:\n",
    "            node = np.random.randint(0, dgl_g.num_nodes())\n",
    "            # A = np.random.randint(0, a_size)\n",
    "            xfers = g.available_xfers(context=quartz_context, node=g.get_node_from_id(id=node))\n",
    "            if xfers != []:\n",
    "                A = random.choice(xfers)\n",
    "            else:\n",
    "                A = np.random.randint(0, a_size)\n",
    "            #print(\"random\")\n",
    "            \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = self.q_net(dgl_g)\n",
    "            # print(pred.shape)\n",
    "            Qs, As = torch.max(pred, dim=1)\n",
    "            # Qs, As = torch.max(pred)\n",
    "            # print(Qs)\n",
    "            # print(As)\n",
    "            # Q, node = torch.max(Qs, dim = 0, keepdim = True)\n",
    "            Q, node = torch.max(Qs, dim = 0)\n",
    "            # print(node)\n",
    "            A = As[node]                 \n",
    "        \n",
    "        # print(node)\n",
    "        # print(A)\n",
    "        return node, A\n",
    "    \n",
    "\n",
    "    def train(self, data, batch_size):\n",
    "        losses = 0\n",
    "        pred_rs = []\n",
    "        target_rs = []\n",
    "        for i in range(batch_size):\n",
    "            s, node, a, r, s_next = data.get_data()\n",
    "\n",
    "            pred = self.q_net(s)\n",
    "            pred_r = pred[node][a]\n",
    "            #s_a = s_as.gather(1, a)\n",
    "\n",
    "            if s_next == None:\n",
    "                target_r = torch.tensor(-1.0)\n",
    "            else:\n",
    "                # TODO: modify this part\n",
    "                q_next = self.target_net(s_next).detach()\n",
    "                q_next_r = q_next[node][a]\n",
    "                # print(q_next.shape)\n",
    "                target_r = r + self.gamma * q_next_r\n",
    "            \n",
    "            pred_rs.append(pred_r)\n",
    "            target_rs.append(target_r)\n",
    "        loss = self.loss_fn(torch.stack(pred_rs), torch.stack(target_rs))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        for param in self.q_net.parameters():\n",
    "            param.grad.data.clamp_(-1,1)\n",
    "        self.optimizer.step()\n",
    "              \n",
    "        return loss.item()    \n",
    "\n",
    "    \n",
    "class QData:\n",
    "    def __init__(self):\n",
    "        self.data = deque(maxlen=100000)\n",
    "        \n",
    "    def add_data(self, d):\n",
    "        self.data.append(d)\n",
    "        \n",
    "    def get_data(self):\n",
    "        s = random.sample(self.data, 1)[0]\n",
    "        #print(s)\n",
    "        return s[0],s[1],s[2],s[3],s[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f168484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "class QConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, inter_dim, out_feat):\n",
    "        super(QConv, self).__init__()\n",
    "        self.linear2 = nn.Linear(in_feat + inter_dim, out_feat)\n",
    "        self.linear1 = nn.Linear(in_feat + 3, inter_dim, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.linear2.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        #print(f'node h {edges.src[\"h\"].shape}')\n",
    "        #print(f'node w {edges.data[\"w\"].shape}')\n",
    "        return {'m': torch.cat([edges.src['h'], edges.data['w']], dim=1)}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        #print(f'node m {nodes.mailbox[\"m\"].shape}')\n",
    "        tmp = self.linear1(nodes.mailbox['m'])\n",
    "        tmp = F.leaky_relu(tmp)\n",
    "        h = torch.mean(tmp, dim=1)\n",
    "        return {'h_N': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        g.ndata['h'] = h\n",
    "        #g.edata['w'] = w #self.embed(torch.unsqueeze(w,1))\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        h_N = g.ndata['h_N']\n",
    "        h_total = torch.cat([h, h_N], dim=1)\n",
    "        return self.linear2(h_total)\n",
    "\n",
    "\n",
    "\n",
    "class QGNN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, inter_dim):\n",
    "        super(QGNN, self).__init__()\n",
    "        self.conv1 = QConv(in_feats, inter_dim, h_feats)\n",
    "        self.conv2 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv3 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv4 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv5 = QConv(h_feats, inter_dim, num_classes)\n",
    "        self.embedding = nn.Embedding(in_feats, in_feats)\n",
    "    \n",
    "    def forward(self, g):\n",
    "        #print(g.ndata['gate_type'])\n",
    "        #print(self.embedding)\n",
    "        g.ndata['h'] = self.embedding(g.ndata['gate_type'])\n",
    "        w = torch.cat([torch.unsqueeze(g.edata['src_idx'],1),torch.unsqueeze(g.edata['dst_idx'],1),torch.unsqueeze(g.edata['reversed'],1)],dim = 1)\n",
    "        g.edata['w'] = w \n",
    "        h = self.conv1(g, g.ndata['h'])\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv4(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv5(g, h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819ecf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraining using tof_3 circuit\n",
    "# Preparaing data\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def get_dataset(i):\n",
    "    dag_i = parser.load_qasm(filename=\"barenco_tof_3_opt_path/subst_history_\" + str(i) + \".qasm\")\n",
    "    graph = quartz.PyGraph(context=quartz_context, dag=dag_i)\n",
    "    dgl_graph = graph.to_dgl_graph()\n",
    "    appliable_xfer_matrix = graph.get_available_xfers_matrix(context=quartz_context)\n",
    "    dgl_graph.ndata['label'] = torch.tensor(appliable_xfer_matrix,dtype=torch.float)\n",
    "    return dgl_graph\n",
    "\n",
    "idx_list = list(range(40))\n",
    "with ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    results = executor.map(get_dataset, idx_list)\n",
    "\n",
    "opt_path_dgls = [r for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6a7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(g, model, lr=0.01, epochs=20):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    all_logits = []\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['gate_type']\n",
    "\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(epochs):\n",
    "        # Forward\n",
    "        logits = model(g)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that we should only compute the losses of the nodes in the training set,\n",
    "        # i.e. with train_mask 1.\n",
    "        #print(logits)\n",
    "        \n",
    "        # loss = torch.nn.MSELoss()(logits[train_mask], labels[train_mask])\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits[train_mask], labels[train_mask])\n",
    "        pred = logits > 0.5\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        train_recall = torch.sum((torch.logical_and((pred[train_mask] == 1), (labels[train_mask] == 1))).float()) / torch.sum((labels[train_mask] == 1).float())\n",
    "        val_recall = torch.sum((torch.logical_and((pred[val_mask] == 1), (labels[val_mask] == 1))).float()) / torch.sum((labels[val_mask] == 1).float())\n",
    "        test_recall = torch.sum((torch.logical_and((pred[test_mask] == 1), (labels[test_mask] == 1))).float()) / torch.sum((labels[test_mask] == 1).float())\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_logits.append(logits.detach())\n",
    "\n",
    "        # TODO: print out false negative\n",
    "        if e % 1 == 0:\n",
    "            print('In epoch {}, loss: {:.5f}, train acc: {:.5f}, train recall: {:.5f}, val acc: {:.5f} (best {:.5f}), val recall: {:.5f}, test acc: {:.5f} (best {:.5f}), test recall: {:.5f}'.format(\n",
    "                e, loss, train_acc, train_recall, val_acc, best_val_acc,val_recall, test_acc, best_test_acc, test_recall))\n",
    "\n",
    "def test(*, filename):\n",
    "    test_dag = parser.load_qasm(filename=filename)\n",
    "    test_graph = quartz.PyGraph(context=quartz_context, dag=test_dag)\n",
    "    test_graph_dgl = test_graph.to_dgl_graph()\n",
    "    appliable_xfer_matrix = test_graph.get_available_xfers_matrix(context=quartz_context)\n",
    "    test_graph_dgl.ndata['label'] = torch.tensor(appliable_xfer_matrix,dtype=torch.float)\n",
    "    labels = test_graph_dgl.ndata['label']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(test_graph_dgl)\n",
    "        pred = logits > 0.5\n",
    "        test_acc = (pred == labels).float().mean()\n",
    "        print(f\"test_acc: {test_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b091986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 41.77746, train acc: 0.92051, train recall: 0.14873, val acc: 0.91930 (best 0.91930), val recall: 0.14802, test acc: 0.91962 (best 0.91962), test recall: 0.15467\n",
      "In epoch 1, loss: 36.55388, train acc: 0.97359, train recall: 0.53680, val acc: 0.97342 (best 0.97342), val recall: 0.52102, test acc: 0.97356 (best 0.97356), test recall: 0.56336\n",
      "In epoch 2, loss: 31.44315, train acc: 0.95964, train recall: 0.98871, val acc: 0.95964 (best 0.97342), val recall: 0.98875, test acc: 0.95966 (best 0.97356), test recall: 0.99346\n",
      "In epoch 3, loss: 24.47112, train acc: 0.95664, train recall: 0.99226, val acc: 0.95666 (best 0.97342), val recall: 0.99171, test acc: 0.95664 (best 0.97356), test recall: 0.99762\n",
      "In epoch 4, loss: 23.10263, train acc: 0.95355, train recall: 0.99594, val acc: 0.95352 (best 0.97342), val recall: 0.99230, test acc: 0.95351 (best 0.97356), test recall: 1.00000\n",
      "In epoch 5, loss: 22.78488, train acc: 0.95505, train recall: 0.99683, val acc: 0.95510 (best 0.97342), val recall: 0.99171, test acc: 0.95496 (best 0.97356), test recall: 1.00000\n",
      "In epoch 6, loss: 22.39429, train acc: 0.96038, train recall: 0.98668, val acc: 0.96046 (best 0.97342), val recall: 0.98579, test acc: 0.96026 (best 0.97356), test recall: 0.98989\n",
      "In epoch 7, loss: 21.81485, train acc: 0.96715, train recall: 0.98325, val acc: 0.96713 (best 0.97342), val recall: 0.98165, test acc: 0.96704 (best 0.97356), test recall: 0.98989\n",
      "In epoch 8, loss: 21.10652, train acc: 0.97102, train recall: 0.97576, val acc: 0.97104 (best 0.97342), val recall: 0.97276, test acc: 0.97099 (best 0.97356), test recall: 0.98453\n",
      "In epoch 9, loss: 20.49941, train acc: 0.97284, train recall: 0.97335, val acc: 0.97287 (best 0.97342), val recall: 0.97040, test acc: 0.97286 (best 0.97356), test recall: 0.98334\n",
      "In epoch 10, loss: 19.87482, train acc: 0.97314, train recall: 0.97500, val acc: 0.97322 (best 0.97342), val recall: 0.97276, test acc: 0.97312 (best 0.97356), test recall: 0.98572\n",
      "In epoch 11, loss: 19.27224, train acc: 0.97353, train recall: 0.97970, val acc: 0.97359 (best 0.97359), val recall: 0.97869, test acc: 0.97352 (best 0.97352), test recall: 0.98691\n",
      "In epoch 12, loss: 18.80277, train acc: 0.97438, train recall: 0.98198, val acc: 0.97445 (best 0.97445), val recall: 0.98046, test acc: 0.97437 (best 0.97437), test recall: 0.98751\n",
      "In epoch 13, loss: 18.75949, train acc: 0.97393, train recall: 0.98350, val acc: 0.97398 (best 0.97445), val recall: 0.98224, test acc: 0.97391 (best 0.97437), test recall: 0.98751\n",
      "In epoch 14, loss: 18.57690, train acc: 0.97309, train recall: 0.98921, val acc: 0.97313 (best 0.97445), val recall: 0.98697, test acc: 0.97312 (best 0.97437), test recall: 0.99048\n",
      "In epoch 15, loss: 18.37279, train acc: 0.97171, train recall: 0.99264, val acc: 0.97182 (best 0.97445), val recall: 0.99053, test acc: 0.97171 (best 0.97437), test recall: 0.99167\n",
      "In epoch 16, loss: 18.25153, train acc: 0.97071, train recall: 0.99594, val acc: 0.97080 (best 0.97445), val recall: 0.99171, test acc: 0.97074 (best 0.97437), test recall: 0.99584\n",
      "In epoch 17, loss: 18.10985, train acc: 0.97015, train recall: 0.99657, val acc: 0.97022 (best 0.97445), val recall: 0.99171, test acc: 0.97023 (best 0.97437), test recall: 0.99703\n",
      "In epoch 18, loss: 17.92701, train acc: 0.96994, train recall: 0.99695, val acc: 0.97000 (best 0.97445), val recall: 0.99171, test acc: 0.97007 (best 0.97437), test recall: 0.99822\n",
      "In epoch 19, loss: 17.70578, train acc: 0.96999, train recall: 0.99772, val acc: 0.97002 (best 0.97445), val recall: 0.99230, test acc: 0.97010 (best 0.97437), test recall: 1.00000\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "bg = dgl.batch(opt_path_dgls)\n",
    "node_cnt = bg.num_nodes()\n",
    "l = list(range(node_cnt))\n",
    "train_rate = 0.7\n",
    "val_rate = 0.15\n",
    "\n",
    "train_num = int(node_cnt * train_rate)\n",
    "val_num = int(node_cnt * val_rate)\n",
    "test_num = node_cnt - train_num - val_num\n",
    "\n",
    "train_sample = sample(l, train_num)\n",
    "node_left = [n for n in l if n not in train_sample]\n",
    "val_sample = sample(node_left, val_num)\n",
    "test_sample = [n for n in node_left if n not in val_sample]\n",
    "\n",
    "train_mask = [0] * node_cnt\n",
    "val_mask = [0] * node_cnt\n",
    "test_mask = [0] * node_cnt\n",
    "\n",
    "for i in range(node_cnt):\n",
    "    if i in train_sample:\n",
    "        train_mask[i] = 1\n",
    "    elif i in val_sample:\n",
    "        val_mask[i] = 1\n",
    "    elif i in test_sample:\n",
    "        test_mask[i] = 1\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "bg.ndata['train_mask'] = torch.tensor(train_mask,dtype=torch.bool) \n",
    "bg.ndata['val_mask'] = torch.tensor(val_mask,dtype=torch.bool) \n",
    "bg.ndata['test_mask'] = torch.tensor(test_mask,dtype=torch.bool) \n",
    "\n",
    "model = QGNN(26, 64, quartz_context.num_xfers, 64)\n",
    "train_supervised(bg, model, lr=0.01, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db1220b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83627/2293888305.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(-1), None])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:23,  2.57s/it]/tmp/ipykernel_83627/2293888305.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(reward), dgl_new_g])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "74\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "60\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:14<01:06,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "66\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "60\n",
      "62\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "70\n",
      "70\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "67\n",
      "69\n",
      "71\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "69\n",
      "71\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:26<01:09,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "61\n",
      "63\n",
      "65\n",
      "60\n",
      "62\n",
      "62\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:33<00:52,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:34<00:28,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:34<00:16,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "62\n",
      "60\n",
      "62\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "60\n",
      "62\n",
      "64\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "60\n",
      "62\n",
      "64\n",
      "60\n",
      "60\n",
      "62\n",
      "64\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "60\n",
      "62\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:42<00:15,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "62\n",
      "60\n",
      "60\n",
      "60\n",
      "62\n",
      "60\n",
      "62\n",
      "58\n",
      "60\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:45<00:08,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:45<00:03,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:47<00:00,  4.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "\n",
    "agent = QAgent(lr = 1e-2, gamma = 0.9, a_size = 3397, pretrained_model = model)\n",
    "data = QData()\n",
    "\n",
    "replay_times = 10\n",
    "episodes = 10\n",
    "epsilon = 0.3\n",
    "train_epoch = 5\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    rewards = 0\n",
    "    losses = 0\n",
    "    for j in range(replay_times):\n",
    "        count = 0\n",
    "        end = False\n",
    "        g = init_graph\n",
    "        while(count < 10 and not end):\n",
    "            dgl_g = g.to_dgl_graph()\n",
    "            count += 1 \n",
    "            node, A = agent.select_a(g, dgl_g, epsilon)\n",
    "            # print(A)\n",
    "            new_g = g.apply_xfer(xfer=quartz_context.get_xfer_from_id(id=A), node = g.all_nodes()[node])\n",
    "            \n",
    "            if new_g == None:\n",
    "                end = True\n",
    "                data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(-1), None])\n",
    "            \n",
    "            else:\n",
    "                dgl_new_g = new_g.to_dgl_graph()\n",
    "                reward = g.gate_count - new_g.gate_count\n",
    "                                         \n",
    "                data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(reward), dgl_new_g])\n",
    "            \n",
    "                g = new_g\n",
    "                rewards += reward\n",
    "                print(g.gate_count)\n",
    "        \n",
    "\n",
    "    for j in range(train_epoch):\n",
    "        loss = agent.train(data, 3)\n",
    "        losses += loss  \n",
    "        \n",
    "    if epsilon > 0.05 :\n",
    "        epsilon -= 0.0001\n",
    "        \n",
    "\n",
    "    agent.target_net.load_state_dict(agent.q_net.state_dict())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
