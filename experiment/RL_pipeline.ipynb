{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f06b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import quartz\n",
    "quartz_context = quartz.QuartzContext(gate_set=['h', 'cx', 'x', 't', 'tdg'], filename='../bfs_verified_simplified.json')\n",
    "parser = quartz.PyQASMParser(context=quartz_context)\n",
    "my_dag = parser.load_qasm(filename=\"../circuit/example-circuits/barenco_tof_3.qasm\")\n",
    "my_dag.num_qubits, my_dag.num_gates\n",
    "init_graph = quartz.PyGraph(context=quartz_context, dag=my_dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15f25615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gate_type_num = 20\n",
    "class QAgent:\n",
    "    def __init__(self, lr, a_size):\n",
    "        torch.manual_seed(42)\n",
    "        self.q_net = QGNN(gate_type_num, 16, a_size, 16)\n",
    "        self.target_net = copy.deepcopy(self.q_net)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr = lr)\n",
    "        self.a_size = a_size \n",
    "               \n",
    "    def select_a(self, g, e):\n",
    "        a_size = self.a_size\n",
    "        \n",
    "        if random.random() < e:\n",
    "            node = np.random.randint(0, g.num_nodes())\n",
    "            A = np.random.randint(0, a_size)\n",
    "            #print(\"random\")\n",
    "            \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = self.q_net(g)\n",
    "            Qs, As = torch.max(pred)\n",
    "            Q, node = torch.max(Qs, dim = 0, keepdim = True)\n",
    "            A = As[node]                 \n",
    "        \n",
    "        #print(node)\n",
    "        #print(A)\n",
    "        return node, A\n",
    "    \n",
    "\n",
    "    def train(self, data, batch_size):\n",
    "        losses = 0\n",
    "        pred_rs = []\n",
    "        target_rs = []\n",
    "        for i in range(batch_size):\n",
    "            s, node, a, r, s_next = data.get_data()\n",
    "\n",
    "            pred = self.q_net(s)\n",
    "            pred_r = pred[node][a]\n",
    "            #s_a = s_as.gather(1, a)\n",
    "\n",
    "            if s_next == None:\n",
    "                target_r = torch.tensor(-1.0)\n",
    "            else:\n",
    "                q_next = self.target_net(s_next).detach()\n",
    "                target_r = r + self.gamma * q_next\n",
    "            \n",
    "            pred_rs.append(pred_r)\n",
    "            target_rs.append(target_r)\n",
    "        loss = self.loss_fn(torch.stack(pred_rs), torch.stack(target_rs))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        for param in self.q_net.parameters():\n",
    "            param.grad.data.clamp_(-1,1)\n",
    "        self.optimizer.step()\n",
    "              \n",
    "        return loss.item()    \n",
    "\n",
    "    \n",
    "class QData:\n",
    "    def __init__(self):\n",
    "        self.data = deque(maxlen=100000)\n",
    "        \n",
    "    def add_data(self, d):\n",
    "        self.data.append(d)\n",
    "        \n",
    "    def get_data(self):\n",
    "        s = random.sample(self.data, 1)[0]\n",
    "        #print(s)\n",
    "        return s[0],s[1],s[2],s[3],s[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f168484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "class QConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, inter_dim, out_feat):\n",
    "        super(QConv, self).__init__()\n",
    "        self.linear2 = nn.Linear(in_feat + inter_dim, out_feat)\n",
    "        self.linear1 = nn.Linear(in_feat + 3, inter_dim, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.linear1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.linear2.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        #print(f'node h {edges.src[\"h\"].shape}')\n",
    "        #print(f'node w {edges.data[\"w\"].shape}')\n",
    "        return {'m': torch.cat([edges.src['h'], edges.data['w']], dim=1)}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        #print(f'node m {nodes.mailbox[\"m\"].shape}')\n",
    "        tmp = self.linear1(nodes.mailbox['m'])\n",
    "        tmp = F.leaky_relu(tmp)\n",
    "        h = torch.mean(tmp, dim=1)\n",
    "        return {'h_N': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        g.ndata['h'] = h\n",
    "        #g.edata['w'] = w #self.embed(torch.unsqueeze(w,1))\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        h_N = g.ndata['h_N']\n",
    "        h_total = torch.cat([h, h_N], dim=1)\n",
    "        return self.linear2(h_total)\n",
    "\n",
    "\n",
    "\n",
    "class QGNN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, inter_dim):\n",
    "        super(QGNN, self).__init__()\n",
    "        self.conv1 = QConv(in_feats, inter_dim, h_feats)\n",
    "        self.conv2 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv3 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv4 = QConv(h_feats, inter_dim, h_feats)\n",
    "        self.conv5 = QConv(h_feats, inter_dim, num_classes)\n",
    "        self.embedding = nn.Embedding(in_feats, in_feats)\n",
    "    \n",
    "    def forward(self, g):\n",
    "        #print(g.ndata['gate_type'])\n",
    "        #print(self.embedding)\n",
    "        g.ndata['h'] = self.embedding(g.ndata['gate_type'])\n",
    "        w = torch.cat([torch.unsqueeze(g.edata['src_idx'],1),torch.unsqueeze(g.edata['dst_idx'],1),torch.unsqueeze(g.edata['reversed'],1)],dim = 1)\n",
    "        g.edata['w'] = w \n",
    "        h = self.conv1(g, g.ndata['h'])\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv4(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv5(g, h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db1220b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████████▊                                                                                                                                     | 1/10 [00:00<00:01,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766\n",
      "284\n",
      "275\n",
      "266\n",
      "407\n",
      "788\n",
      "216\n",
      "662\n",
      "1078\n",
      "686\n",
      "185\n",
      "356\n",
      "747\n",
      "359\n",
      "713\n",
      "648\n",
      "957\n",
      "859\n",
      "743\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████████████▍                                                                                                       | 3/10 [00:00<00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n",
      "531\n",
      "658\n",
      "121\n",
      "713\n",
      "977\n",
      "378\n",
      "370\n",
      "372\n",
      "332\n",
      "379\n",
      "155\n",
      "840\n",
      "197\n",
      "118\n",
      "880\n",
      "875\n",
      "1112\n",
      "624\n",
      "843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████                                                                          | 5/10 [00:00<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "235\n",
      "193\n",
      "14\n",
      "714\n",
      "909\n",
      "530\n",
      "64\n",
      "564\n",
      "493\n",
      "663\n",
      "852\n",
      "549\n",
      "846\n",
      "171\n",
      "841\n",
      "672\n",
      "906\n",
      "355\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 7/10 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "269\n",
      "248\n",
      "1012\n",
      "61\n",
      "589\n",
      "894\n",
      "131\n",
      "983\n",
      "757\n",
      "1082\n",
      "980\n",
      "164\n",
      "1099\n",
      "267\n",
      "640\n",
      "908\n",
      "191\n",
      "1065\n",
      "883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 9/10 [00:01<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\n",
      "962\n",
      "457\n",
      "979\n",
      "1048\n",
      "505\n",
      "168\n",
      "362\n",
      "676\n",
      "461\n",
      "364\n",
      "18\n",
      "188\n",
      "416\n",
      "1097\n",
      "381\n",
      "132\n",
      "657\n",
      "132\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "\n",
    "agent = QAgent(lr = 1e-3, a_size = 1118)\n",
    "data = QData()\n",
    "\n",
    "replay_times = 10\n",
    "episodes = 10\n",
    "epsilon = 1\n",
    "train_epoch = 5\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    rewards = 0\n",
    "    losses = 0\n",
    "    for j in range(replay_times):\n",
    "        count = 0\n",
    "        end = False\n",
    "        g = init_graph\n",
    "        while(count < 10 and not end):\n",
    "            dgl_g = g.to_dgl_graph()\n",
    "            count += 1 \n",
    "            node, A = agent.select_a(dgl_g, epsilon)\n",
    "            print(A)\n",
    "            new_g = g.apply_xfer(xfer=quartz_context.get_xfer_from_id(id=A), node = g.all_nodes()[node])\n",
    "            \n",
    "            if new_g == None:\n",
    "                end = True\n",
    "                data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(-1), None])\n",
    "            \n",
    "            else:\n",
    "                dgl_new_g = new_g.to_dgl_graph()\n",
    "                reward = g.num_gates() - new_g.num_gates()\n",
    "                                         \n",
    "                data.add_data([dgl_g, torch.tensor(node), torch.tensor(A), torch.tensor(reward), dgl_new_g])\n",
    "            \n",
    "                g = new_g\n",
    "                rewards += reward\n",
    "        \n",
    "\n",
    "    for j in range(train_epoch):\n",
    "        loss = agent.train(data, 3)\n",
    "        losses += loss  \n",
    "        \n",
    "    if epsilon > 0.05 :\n",
    "        epsilon -= 0.0001\n",
    "        \n",
    "\n",
    "    agent.target_net.load_state_dict(agent.q_net.state_dict())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
